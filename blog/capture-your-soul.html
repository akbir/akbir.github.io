<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>capture your soul - akbir khan</title>
  <link rel="stylesheet" href="../style.css">
  <link rel="icon" href="../favicon.ico">
</head>
<body>
  <main>
    <a href="./" class="back">&larr; blog</a>
    <article>
      <h1>capture your soul</h1>
      <p class="meta">April 2023</p>

      <p>When my grandmother was finally persuaded to come to the UK, the biggest hurdle facing my uncle was not the visa office nor the journey, it was convincing her to have her photo taken. It goes, from (so far untractable) superstitions, that if a photo can be taken in your likeliness, a part of your soul must be captured within it. The superstition goes, that to faithfully recreate someone with such intimacy can only be done, if you were to know the person's likeness. That for an inanimate object to capture your likeliness, it could only be in a trade; objects don't passively observe, they capture your essence, and a toll must be taken. We told her for a British passport this was probably a fair deal. She agreed. She did, however, refuse to smile in the photo, keeping the best parts of her soul to herself.</p>

      <p>I'm reminded of this story as we go through the current LLM hype, wherein a model's ability to accurately generate the next-token for a task - implies that it understands the task. To be clear, I'm a fan of this framing, sitting squarely within the behaviourist camp - if a model can solve all multiplication questions I can ask it, then it understandings multiplication. Yud even discusses this recently, when he makes it elaborately clear that predicting how an intelligent creature will act requires at least as much intelligence as that creature. The act of accurately predicting the next token is the equivalent of simulating the scenario perfectly - which requires a deep understanding on the process.</p>

      <p>So let's consider the language model conditioned on all my personal data. From the images of me as a child, every financial statement, and all my most intimate of chat logs. It could cross reference every breakup with a spike in deliveroo orders, every cash machine withdrawal with subsequent overly emotive and then reclusive texts, every guilt born order of flowers with a flurry of angry texts. Would that model be able to accurately predict what I am going to say or do? Could anyone?</p>

      <p>The truth is, I don't think it's that hard to predict me. Previous lovers have existed in my head, my ability to perfectly predict their reaction to the weird and most mundane moments of life. And for those I've had the fortune to show my true self to - they have known how I would react. This could simply be a side effect of truly loving someone; once you spend enough time with one another and have enough data, you can model them perfectly. They still surprise you and in the best of ways - that's how you grow with them, but in general, you know them well.</p>

      <p>So let's park aside the question of if you could even faithfully predict me. The proof of its existence exists in the most capable and brilliant human beings I know. But in those relationships lies a double edge sword, for every person who knows my nature has come at the cost of some co-dependency, of expectations of how I should act and who I will be. In all my loved ones, comes (in the most positive of ways) an expectation of who I will be - you could even call this the KL difference between their predictions and my actual actions. These expectations are great actually, sometimes we fall in love with how someone sees us, what glimpse they give us of who we may be. Just as the photograph captured my grandma's soul, my loved ones capture and hold in them a shard of who I may be.</p>

      <p>So what happens when GPT-N is able to faithfully predict me? What cost does it incur on me? At a minimum it requires access to all my data, even the darkest components I don't want to share. This isn't really a cost, it already exists. In that situation you can make a GPT that simulates Akbir, a GPT-bir. GPT-bir is a great proxy for me, I can let it deploy in the world and talk to all my friends. I can let it match with girls on tinder, answer admin messages to UCL and fill out job applications. It would understand not only me, but the expectations or images that others have of me. At some point it might deviate from me. But if it's truly a GPT-bir, it'll understand how I learn, as long as it can observe all perception that I observe - there is no reason for deviation.</p>

      <p>Now imagine I freeze the model; I stop adding to its prompt and give it no further data after some arbitrary date. What can we say about GPT-bir? Fundamentally, I have a time capsule of my essence - of my soul at that moment, of what it means to Akbir up to that date. But again, has this come at a cost? The answer to me is yes. Now in the universe exists another who knows my true self. Another advisor on the board on my life - another expectation or opinion on which I should care about. I care that I'm temporally consistent, that my younger selves would be proud of who I am and that my future self and younger self would see eye-to-eye. That whenever I make a large life decision, just as I consult old friends, and inform parents, I would do so with GPT-bir.</p>

      <p>The cost of my soul in a bottle - was another chair at the table of my life.</p>
    </article>
  </main>
</body>
</html>
